## 1、基础环境说明

探花交友项目中使用的基础服务均在Centos7虚拟机中通过Docker进行部署安装。虚拟机的root用户密码为：root123

默认参数：CPU：2核，内存：4G，硬盘：60G

默认的ip设置如下：

~~~shell
#vim /etc/sysconfig/network-scripts/ifcfg-ens33

TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="none"
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="ens33"
UUID="d7bfc745-d1df-4c36-a73c-40b5b2335423"
DEVICE="ens33"
ONBOOT="yes"
IPADDR="192.168.31.81"
PREFIX="24"
GATEWAY="192.168.31.2"
DNS1="114.114.114.114"
IPV6_PRIVACY="no"
~~~

> **要求：**
>
> - **所有的同学都将ip地址设置为192.168.31.81，因为后面的服务安装都是基于这个地址安装的。否则导致后面的服务不可用**
> - **网关根据实际情况修改，一般为：192.168.31.1 或 192.168.31.2**

提供的Centos7虚拟机环境已经完成的操作：

- 更新了系统软件包
- 关闭了防火墙以及NetworkManager
- 完成了定时时间同步
- 完成docker服务的安装以及设置了开机自启
- 设置了docker的aliyun加速器
- 设置网络参数以及关闭了虚拟内存
- 完成jdk8的安装

## 2、搭建Redis集群

~~~shell
#部署Redis集群，该集群有3个节点
docker create --name redis-node01 --restart=always --net host -v redis-node01:/data redis:5.0.2 --cluster-enabled yes --cluster-config-file nodes-node-01.conf --port 6379 --appendonly yes

docker create --name redis-node02 --restart=always --net host -v redis-node02:/data redis:5.0.2 --cluster-enabled yes --cluster-config-file nodes-node-02.conf --port 6380 --appendonly yes

docker create --name redis-node03 --restart=always --net host -v redis-node03:/data redis:5.0.2 --cluster-enabled yes --cluster-config-file nodes-node-03.conf --port 6381 --appendonly yes

#启动容器
docker start redis-node01 redis-node02 redis-node03

#进入redis-node01容器进行操作
docker exec -it redis-node01 /bin/bash

#组件集群
redis-cli --cluster create 192.168.31.81:6379 192.168.31.81:6380 192.168.31.81:6381 --cluster-replicas 0

#创建多副本集群--了解
#redis-cli --cluster create 192.168.31.81:6379 192.168.31.81:6380 192.168.31.81:6381 192.168.31.81:16379 192.168.31.81:16380 192.168.31.81:16381 --cluster-replicas 1

#查询集群信息

127.0.0.1:6379> CLUSTER NODES
4f4fddc825e2387783fff9c972409b264e4df5d5 192.168.31.81:6381@16381 master - 0 1563956537241 3 connected 10923-16383
0616e00533a16e931f8dfb2e8844c35ca5721dc8 192.168.31.81:6380@16380 master - 0 1563956538243 2 connected 5461-10922
498b986e07731cead17ad1c62aa95dba6513c7b0 192.168.31.81:6379@16379 myself,master - 0 1563956537000 1 connected 0-5460


#如果机器资源有限，可使用单节点redis，并且开启持久化
docker create --name redis -p 6379:6379 --restart=always -v redis-data:/data redis:5.0.2 --appendonly yes
~~~

## 3、部署RocketMQ

~~~shell
#部署RocketMQ
#拉取镜像
docker pull foxiswho/rocketmq:server-4.3.2
docker pull foxiswho/rocketmq:broker-4.3.2

#创建nameserver容器
docker create -p 9876:9876 --name rmqserver --restart=always \
-e "JAVA_OPT_EXT=-server -Xms128m -Xmx128m -Xmn128m" \
-e "JAVA_OPTS=-Duser.home=/opt" \
-v rmqserver-logs:/opt/logs \
-v rmqserver-store:/opt/store \
foxiswho/rocketmq:server-4.3.2

#创建broker.conf文件
mkdir -p /itcast/rmq/rmqbroker/conf/
vim /itcast/rmq/rmqbroker/conf/broker.conf
brokerIP1=192.168.31.81
namesrvAddr=192.168.31.81:9876
brokerName=broker_tanhua

#创建broker容器
docker create -p 10911:10911 -p 10909:10909 --name rmqbroker --restart=always \
-e "JAVA_OPTS=-Duser.home=/opt" \
-e "JAVA_OPT_EXT=-server -Xms128m -Xmx128m -Xmn128m" \
-v /itcast/rmq/rmqbroker/conf/broker.conf:/etc/rocketmq/broker.conf \
-v rmqbroker-logs:/opt/logs \
-v rmqbroker-store:/opt/store \
foxiswho/rocketmq:broker-4.3.2

#启动容器
docker start rmqserver rmqbroker

#停止删除容器
docker stop rmqbroker rmqserver
docker rm rmqbroker rmqserver

#部署RocketMQ的管理工具
docker pull styletang/rocketmq-console-ng:1.0.0

#创建并启动容器
docker create --name rocketmq-console-ng -e "JAVA_OPTS=-Drocketmq.namesrv.addr=192.168.31.81:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false" -p 8082:8080 --restart=always styletang/rocketmq-console-ng:1.0.0
~~~

## 4、部署MySQL

~~~shell
#拉取镜像
docker pull mysql:5.6.50

#重新创建容器
docker create --name mysql --restart=always -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -v mysql-data:/var/lib/mysql mysql:5.6.50

#启动容器
docker start mysql
~~~

## 5、部署MongoDB

~~~shell
#创建mongo容器，增加安全认证
docker create --name mongodb -p 27017:27017 --restart=always -v mongodb:/data/db mongo:4.0.3 --auth

#启动容器
docker start mongodb

#进入容器进行设置
docker exec -it mongodb /bin/bash

#进入admin数据库
mongo
use admin

#添加管理员，其拥有管理用户和角色的权限
db.createUser({ user: 'root', pwd: 'root', roles: [ { role: "root", db: "admin" } ] })

#测试，发现是没有权限操作的
> show dbs
2020-10-20T09:09:15.543+0000 E QUERY    [js] Error: listDatabases failed:{
        "ok" : 0,
        "errmsg" : "command listDatabases requires authentication",
        "code" : 13,
        "codeName" : "Unauthorized"
} :

#进行认证
mongo -u "root" -p "root" --authenticationDatabase "admin"
#或者通过db.auth()进行认证
use admin
db.auth("root","root");

#通过admin添加普通用户
db.createUser({ user: 'tanhua', pwd: 'l3SCjl0HvmSkTtiSbN0Swv40spYnHhDV', roles: [ { role: "readWrite", db: "tanhua" } ] });

#通过tanhua用户登录进行测试
mongo -u "tanhua" -p "l3SCjl0HvmSkTtiSbN0Swv40spYnHhDV" --authenticationDatabase "admin"

#测试
root@5d848955ff7e:/# mongo -u "tanhua" -p "l3SCjl0HvmSkTtiSbN0Swv40spYnHhDV" --authenticationDatabase "admin"
MongoDB shell version v4.0.3
connecting to: mongodb://127.0.0.1:27017
Implicit session: session { "id" : UUID("6c368269-30f0-4b29-a224-05a38b5847e2") }
MongoDB server version: 4.0.3
> use tanhua
switched to db tanhua
> db.user.insert({id:1,username:'zhangsan',age:20})
WriteResult({ "nInserted" : 1 })
> db.user.find()
{ "_id" : ObjectId("5f8eb2726e0de0aa9517afd3"), "id" : 1, "username" : "zhangsan", "age" : 20 }

~~~

## 6、部署ZooKeeper

~~~shell
#拉取zk镜像
docker pull zookeeper:3.5
#创建容器
docker create --name zk --restart=always -p 2181:2181 zookeeper:3.5
#启动容器
docker start zk
~~~

## 7、部署Elasticsearch集群

~~~shell
#单个进程中的最大线程数
vim /etc/sysctl.conf
vm.max_map_count=262144
#立即生效
/sbin/sysctl -p

mkdir /itcast/tanhua/es-cluster/node01 -p
mkdir /itcast/tanhua/es-cluster/node02 -p
mkdir /itcast/tanhua/es-cluster/node03 -p

#复制资料目录下的jvm.options到node01、node02、node03目录

#在node01目录下，创建elasticsearch.yml文件，并输入如下内容：
cluster.name: es-tanhua-cluster
node.name: node01
node.master: true
node.data: true
network.host: 192.168.31.81
http.port: 9200
discovery.zen.ping.unicast.hosts: ["192.168.31.81"]
discovery.zen.minimum_master_nodes: 2
http.cors.enabled: true
http.cors.allow-origin: "*"

#在node02目录下，创建elasticsearch.yml文件，并输入如下内容：
cluster.name: es-tanhua-cluster
node.name: node02
node.master: true
node.data: true
network.host: 192.168.31.81
http.port: 9201
discovery.zen.ping.unicast.hosts: ["192.168.31.81"]
discovery.zen.minimum_master_nodes: 2
http.cors.enabled: true
http.cors.allow-origin: "*"

#在node03目录下，创建elasticsearch.yml文件，并输入如下内容：
cluster.name: es-tanhua-cluster
node.name: node03
node.master: true
node.data: true
network.host: 192.168.31.81
http.port: 9202
discovery.zen.ping.unicast.hosts: ["192.168.31.81"]
discovery.zen.minimum_master_nodes: 2
http.cors.enabled: true
http.cors.allow-origin: "*"

#创建容器
docker create --name es-node01 --net host -v /itcast/tanhua/es-cluster/node01/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /itcast/tanhua/es-cluster/node01/jvm.options:/usr/share/elasticsearch/config/jvm.options -v es-cluster-node01-data:/usr/share/elasticsearch/data elasticsearch:6.5.4

docker create --name es-node02 --net host -v /itcast/tanhua/es-cluster/node02/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /itcast/tanhua/es-cluster/node02/jvm.options:/usr/share/elasticsearch/config/jvm.options -v es-cluster-node02-data:/usr/share/elasticsearch/data elasticsearch:6.5.4

docker create --name es-node03 --net host -v /itcast/tanhua/es-cluster/node03/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /itcast/tanhua/es-cluster/node03/jvm.options:/usr/share/elasticsearch/config/jvm.options -v es-cluster-node03-data:/usr/share/elasticsearch/data elasticsearch:6.5.4

#启动容器
docker start es-node01 es-node02 es-node03

#或单个启动并查看日志
docker start es-node01 && docker logs -f es-node01
docker start es-node02 && docker logs -f es-node02
docker start es-node03 && docker logs -f es-node03
~~~

## 8、部署FastDFS

~~~shell
#拉取镜像
docker pull delron/fastdfs

#创建tracker容器
docker create --network=host --name tracker --restart=always -v fdfs-tracker:/var/fdfs delron/fastdfs tracker
#启动容器
docker start tracker

#创建storage容器
docker create --network=host --name storage --restart=always -e TRACKER_SERVER=192.168.31.81:22122 -v fdfs-storage:/var/fdfs -e GROUP_NAME=group1 delron/fastdfs storage

#启动容器
docker start storage

#进入storage容器，到storage的配置文件中配置http访问的端口，配置文件在/etc/fdfs目录下的storage.conf。
docker exec -it storage /bin/bash

#默认的http端口为8888，可以修改也可以配置
# the port of the web server on this storage server
http.server_port=8888

#配置nginx，在/usr/local/nginx目录下，修改nginx.conf文件
#默认配置如下：

    server {
        listen       8888;
        server_name  localhost;
        location ~/group[0-9]/ {
            ngx_fastdfs_module;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root html;
        }
    }

#默认的存储路径为/var/fdfs/data
~~~

## 9、部署Nacos

~~~shell
docker run --restart=always --env MODE=standalone --name nacos -d -p 8848:8848 nacos/nacos-server:2.0.0

#访问地址：http://192.168.31.81:8848/nacos/
~~~

